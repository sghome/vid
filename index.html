<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Audio Visualization</title>
    <script src="https://cdn.jsdelivr.net/npm/@tonejs/midi@2.0.28/build/Midi.min.js"></script>
    <style>
        * {
            box-sizing: border-box;
        }

        html,
        body {
            margin: 0;
            min-height: 100vh;
            overflow: hidden;
            background: repeating-radial-gradient(
                circle at center,
                #444 0 10%,
                #111 10% 20%
            );
            touch-action: none;
        }

        canvas {
            width: 100%;
            height: auto;
            object-fit: contain;
        }
    </style>
</head>

<body>
    <canvas id="canvas"></canvas>

    <script>
        let audio, audioContext, audioSrc;
        let analyser, analyserBufferLength;
        let fftSize = 8192;
        let smoothingTimeConstant = 0.65;
        let audioAmplitude;

        const glCanvas = document.getElementById('canvas');
        const gl = glCanvas.getContext('webgl2');
        const dpr = Math.max(.5, .5 * window.devicePixelRatio);
        const touches = new Map();

        const vertexSource = `#version 300 es
            precision highp float;
            in vec2 position;
            uniform float audioAmplitude;

            void main(void) {
                vec2 newPosition = position + normalize(position) * audioAmplitude * 0.1;
                gl_Position = vec4(newPosition, 0., 1.);
            }
        `;

        const fragmentSource = `#version 300 es
            precision highp float;
            out vec4 fragColor;
            uniform vec2 resolution;
            uniform vec2 touch;
            uniform float time;
            uniform int pointerCount;
            uniform float audioAmplitude;
            uniform vec3 color;
            uniform vec2 offset;
            uniform float scale;
            uniform float rhythmAmplitude;

            // Resto del fragment shader...

            void main(void) {
                // Código del fragment shader...
            }
        `;

        let time;
        let buffer;
        let program;
        let touchLoc;
        let resolutionLoc;
        let pointerCountLoc;
        let vertices = [];
        let touching = false;

        let midiInfo; // Variable para almacenar información del MIDI

        async function loadAndProcessMidi(midiFilePath) {
            const response = await fetch(midiFilePath);
            const midiData = await response.arrayBuffer();
            const midi = new Midi(midiData);

            // Guarda la información del MIDI para su uso posterior
            midiInfo = {
                chords: midi.tracks[0].notes.map((note) => note.name),
                tempo: midi.header.tempos[0].bpm,
                // Puedes agregar más propiedades según sea necesario
            };

            // Resto de la función...
        }

        function setup() {
            const vs = gl.createShader(gl.VERTEX_SHADER);
            const fs = gl.createShader(gl.FRAGMENT_SHADER);

            program = gl.createProgram();

            compile(vs, vertexSource);
            compile(fs, fragmentSource);

            gl.attachShader(program, vs);
            gl.attachShader(program, fs);
            gl.linkProgram(program);

            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error(gl.getProgramInfoLog(program));
            }

            vertices = [-1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0];

            buffer = gl.createBuffer();

            gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW);

            const position = gl.getAttribLocation(program, "position");

            gl.enableVertexAttribArray(position);
            gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 0, 0);

            time = gl.getUniformLocation(program, "time");
            touchLoc = gl.getUniformLocation(program, "touch");
            pointerCountLoc = gl.getUniformLocation(program, "pointerCount");
            resolutionLoc = gl.getUniformLocation(program, "resolution");
        }

        function compile(shader, source) {
            gl.shaderSource(shader, source);
            gl.compileShader(shader);

            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error(gl.getShaderInfoLog(shader));
            }
        }

        function draw(now) {
            gl.clearColor(0, 0, 0, 1);
            gl.clear(gl.COLOR_BUFFER_BIT);

            gl.useProgram(program);
            gl.bindBuffer(gl.ARRAY_BUFFER, null);
            gl.bindBuffer(gl.ARRAY_BUFFER, buffer);

            gl.uniform1f(time, now * 0.001);
            gl.uniform2f(touchLoc, ...getTouches());
            gl.uniform1i(pointerCountLoc, touches.size);
            gl.uniform2f(resolutionLoc, glCanvas.width, glCanvas.height);
            gl.drawArrays(gl.TRIANGLES, 0, vertices.length * 0.5);
        }

        function getTouches() {
            if (!touches.size) {
                return [0, 0];
            }

            for (let [id, t] of touches) {
                const result = [dpr * t.clientX, dpr * (innerHeight - t.clientY)];
                return result;
            }
        }

        function loop(now) {
            draw(now);
            requestAnimationFrame(loop);
        }

        function init() {
            setup();
            resize();
            loop(0);

            document.cookie = "parking_session=value; samesite=None; secure";
            document.body.addEventListener('click', initAudio);
        }

        async function initAudio() {
            await loadAndProcessMidi('https://sghome.github.io/mp3/go.mid');
            audioSetup('https://cdn.glitch.global/764bc5af-2031-4a40-82a5-7a4337618c33/media-674193e0.mp3');
            document.body.removeEventListener('click', initAudio);
        }

        document.body.onload = init;
        window.onresize = resize;

        glCanvas.onpointerdown = e => {
            if (touches.size === 2) touches.clear();
            touching = true;
            touches.set(e.pointerId, e);
        };

        glCanvas.onpointermove = e => {
            if (!touching) return;
            touches.set(e.pointerId, e);
        };

        glCanvas.onpointerup = e => {
            touching = false;
            touches.clear();
        };

        glCanvas.onpointerout = e => {
            if (touches.size === 2) return;
            touching = false;
            touches.clear();
        };

        document.documentElement.onkeyup = e => {
            console.log(e.key);
            if (e.key === "v") {
                touches.set(1, { clientX: 100, clientY: 100 });
                touches.set(2, { clientX: 200, clientY: 200 });
            } else if (e.key === "g") {
                touches.clear();
            }
        };

        function audioSetup(url) {
            audio = new Audio();
            audio.src = url;
            audio.controls = false;
            audio.loop = true;
            audio.autoplay = true;
            audio.crossOrigin = 'anonymous';
            audio.addEventListener('canplaythrough', audioLoaded, false);

            audioContext = new (window.AudioContext || window.webkitAudioContext)();

            analyser = audioContext.createAnalyser();
            analyser.connect(audioContext.destination);
            analyser.smoothingTimeConstant = smoothingTimeConstant;
            analyser.fftSize = fftSize;
            analyserBufferLength = analyser.frequencyBinCount;

            audioSrc = audioContext.createMediaElementSource(audio);
            audioSrc.connect(analyser);
        }

        function audioLoaded() {
            audio.play();
            animate();
        }

        function animate() {
            const dataArray = new Uint8Array(analyserBufferLength);
            analyser.getByteFrequencyData(dataArray);

            // Normaliza la amplitud del audio entre 0 y 1
            const audioAmplitude = dataArray.reduce((a, b) => a + b, 0) / (analyserBufferLength * 255);

            // Actualiza los valores en el shader según la amplitud del audio
            gl.uniform1f(gl.getUniformLocation(program, "audioAmplitude"), audioAmplitude);

            // Modifica la posición y escala de los elementos según la amplitud
            gl.uniform2f(gl.getUniformLocation(program, "offset"), audioAmplitude * 2.0, audioAmplitude * 2.0);
            gl.uniform1f(gl.getUniformLocation(program, "scale"), 1.0 + audioAmplitude);

            // Cambia el color en función de la amplitud
            const color = getColorFromAmplitude(audioAmplitude);
            gl.uniform3f(gl.getUniformLocation(program, "color"), color[0], color[1], color[2]);

            // Agrega efectos de sonido adicionales según la amplitud
            playSoundEffect(audioAmplitude);

            // Puedes agregar aquí la lógica para interactuar con el MIDI y actualizar el shader
            interactWithMidi();

            requestAnimationFrame(animate);
        }

        // Función para interactuar con el archivo MIDI y actualizar el shader
        function interactWithMidi() {
            const currentChordIndex = getCurrentChordIndex();
            const currentChord = midiInfo.chords[currentChordIndex];

            // Obtén el color asociado al acorde
            const chordColor = chordToColor(currentChord);

            // Pasa el color al shader
            gl.uniform3f(gl.getUniformLocation(program, "color"), chordColor[0], chordColor[1], chordColor[2]);

            // Ajusta la posición y escala de los elementos según la frecuencia del acorde
            const chordFrequency = getChordFrequency(currentChord);
            const positionScaleFactor = map(chordFrequency, 0, 1, 0.5, 2.0);
            gl.uniform2f(gl.getUniformLocation(program, "offset"), audioAmplitude * positionScaleFactor, audioAmplitude * positionScaleFactor);
            gl.uniform1f(gl.getUniformLocation(program, "scale"), 1.0 + audioAmplitude);

            // Genera ritmo según el tempo del MIDI
            const tempo = midiInfo.tempo;
            const beatsPerMinute = tempo;
            const beatsPerSecond = beatsPerMinute / 60;
            const secondsPerBeat = 1 / beatsPerSecond;
            const rhythmAmplitude = Math.sin(audioContext.currentTime * 2 * Math.PI * beatsPerSecond);

            // Utiliza rhythmAmplitude para modular otras propiedades del shader
            gl.uniform1f(gl.getUniformLocation(program, "rhythmAmplitude"), rhythmAmplitude);

            // Puedes ajustar otras propiedades del shader según tu lógica
            // por ejemplo, la intensidad de efectos visuales o la velocidad de animación
            // gl.uniform1f(gl.getUniformLocation(program, "otraPropiedad"), rhythmAmplitude * 0.5);

            // Puedes agregar más lógica según sea necesario
        }

        // Función para obtener el índice del acorde actual del MIDI
        function getCurrentChordIndex() {
            const currentTime = audioContext.currentTime;
            const beatsPerMinute = midiInfo.tempo;
            const beatsPerSecond = beatsPerMinute / 60;
            const secondsPerBeat = 1 / beatsPerSecond;
            const totalBeats = currentTime / secondsPerBeat;

            // Calcula el índice del acorde actual
            const currentChordIndex = Math.floor(totalBeats) % midiInfo.chords.length;

            return currentChordIndex;
        }

        // Función para convertir un acorde en un color RGB
        function chordToColor(chord) {
            // Lógica para asignar colores a los acordes
            // Puedes usar el círculo de acordes o algún otro método
            // Ajusta los valores de r, g, b según tu preferencia
            const r = 1.0;
            const g = 0.5;
           
const b = 0.2;

            return [r, g, b];
        }

        // Función para obtener la frecuencia asociada a un acorde
        function getChordFrequency(chord) {
            // Lógica para determinar la frecuencia del acorde
            // Puedes mapear los acordes a valores de frecuencia según tus preferencias
            // Ajusta los valores según tu visión creativa
            return map(chord.intensity, 0, 1, 0.2, 0.8);
        }

        // Función de mapeo para ajustar valores de un rango a otro
        function map(value, inMin, inMax, outMin, outMax) {
            return (value - inMin) * (outMax - outMin) / (inMax - inMin) + outMin;
        }

        // Función para obtener un color RGB a partir de la amplitud del audio
        function getColorFromAmplitude(amplitude) {
            // Ajusta los valores de color según la amplitud del audio
            const r = 0.5 + amplitude * 0.5;
            const g = 0.2 + amplitude * 0.8;
            const b = 0.1 + amplitude * 0.9;

            return [r, g, b];
        }

        // Función para reproducir efectos de sonido adicionales según la amplitud
        function playSoundEffect(amplitude) {
            // Ajusta la reproducción de efectos de sonido según la amplitud
            const volume = amplitude * 2.0; // Ajusta el volumen según la amplitud

            // Ejemplo: reproducir un efecto de sonido adicional
            // Comenta o elimina la línea siguiente para evitar cargar el recurso específico
            // if (volume > 0.5) {
            //     playAdditionalSound('https://ejemplo.com/efecto-adicional.mp3', volume);
            // }

            // Puedes agregar más lógica y efectos de sonido según tus necesidades
        }

        // Función para reproducir un efecto de sonido adicional
        function playAdditionalSound(url, volume) {
            const additionalAudio = new Audio(url);
            additionalAudio.volume = Math.min(1.0, volume); // Ajusta el volumen entre 0 y 1
            additionalAudio.play();
        }
    </script>
</body>
</html>

